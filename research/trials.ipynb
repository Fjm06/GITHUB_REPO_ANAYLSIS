{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dda7c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saad\n"
     ]
    }
   ],
   "source": [
    "print('Saad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5d77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings,ChatHuggingFace,HuggingFaceEndpoint\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3740146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ChatBotProjects\\\\DecoderBot\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b4642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir sample_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2a1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f35b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo 'd:\\\\ChatBotProjects\\\\DecoderBot\\\\research\\\\MedicalChatBot\\\\.git'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "repo_path = \"MedicalChatBot\"\n",
    "Repo.clone_from('https://github.com/M-SAAD-BIN-MAZHAR/MedicalChatBot',to_path=repo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8f3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=GenericLoader.from_filesystem(repo_path,\n",
    "                                     glob='**/*.py',\n",
    "                                     suffixes=['.py'],\n",
    "                                     parser=LanguageParser(language=Language.PYTHON,parser_threshold=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac933d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498cba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_splitter=RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON,chunk_size=2000,chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b9518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=documents_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "957b9fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "807cfebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings,HuggingFaceEndpoint\n",
    "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "llm=HuggingFaceEndpoint(\n",
    "    repo_id='mistralai/Mistral-7B-Instruct-v0.3',\n",
    "    task='text-generation'\n",
    ")\n",
    "model=ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76056654",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb=Chroma.from_documents(texts,embedding=embeddings,persist_directory='./data')\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64fc5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationSummaryMemory(llm=model,memory_key='chat_history',return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53f115c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=ConversationalRetrievalChain.from_llm(model,retriever=vectordb.as_retriever(search_kwargs={'k':3}) ,memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b56b2bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The `text_split` method is a function that splits a given text into smaller chunks. It uses the `RecursiveCharacterTextSplitter` class from the `langchain.text_splitter` module. The method takes the text to be split as an argument and returns a list of smaller text chunks, each with a specified chunk size and overlap. The chunk size is set to 500 characters, and the overlap is set to 20 characters. This function is used to process large texts, such as those loaded from PDF files, into manageable chunks for further processing.\n"
     ]
    }
   ],
   "source": [
    "question='What is text_spliiter method'\n",
    "result=qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd8253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
